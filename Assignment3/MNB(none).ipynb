{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import math\n",
    "from nltk.corpus import stopwords \n",
    "from nltk.tokenize import word_tokenize\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TrainMultinomialNB(C, D):\n",
    "    \n",
    "    no_remove = \"\"\n",
    "    punctuations = list(string.punctuation)\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words_punc = stopwords.words('english') + list(string.punctuation)\n",
    "    myFilter = no_remove\n",
    "    \n",
    "    \n",
    "    # create a dictionary to read all documents' full path and make its class as keys\n",
    "    files = {c: [] for c in C}\n",
    "    # r: root, d: directories, f: files\n",
    "    for r, d, f in os.walk(D):\n",
    "        for file in f:\n",
    "            for c in C:\n",
    "                if '.'+c in file:\n",
    "                    files[c].append(os.path.join(r, file))\n",
    "    \n",
    "    \n",
    "    \n",
    "    # create a dictionary to read all words from each class\n",
    "    vocabulary = {}\n",
    "    for c in C:                                                                           # for each class\n",
    "        for path in files[c]:                                                             # for each document in the class\n",
    "            file = open(path, 'r', encoding='utf-8', errors='ignore')                     # ignore some decoding issues (especialy in emails)\n",
    "            text = file.read().lower()                                                    # read into a string: 'text'\n",
    "            file.close()\n",
    "            tokens = word_tokenize(text)\n",
    "            filtered_keys = [i for i in word_tokenize(text) if i not in myFilter]         #\n",
    "\n",
    "            for k in filtered_keys:                                                       # apply to dictionary\n",
    "                if k in vocabulary:\n",
    "                    if c in vocabulary[k]:\n",
    "                        vocabulary[k][c] += 1\n",
    "                    else:\n",
    "                        vocabulary[k][c] = 1\n",
    "                else:\n",
    "                    vocabulary[k] = {c: 1}\n",
    "    # regular vocabulary dict by adding 0 value\n",
    "    for k in vocabulary:\n",
    "        for c in C:\n",
    "            if c not in vocabulary[k]:\n",
    "                vocabulary[k][c] = 0\n",
    "    \n",
    "    \n",
    "    \n",
    "    # prior probability of each class\n",
    "    prior = {}\n",
    "    totalFiles = 0;\n",
    "    for c in C:                                                                           # calculate total number of documents\n",
    "        totalFiles += len(files[c])\n",
    "    for c in C:\n",
    "        prior[c] = len(files[c]) / totalFiles\n",
    "    \n",
    "    \n",
    "    \n",
    "    # calculate prabability of each word/term\n",
    "    condprob = copy.deepcopy(vocabulary)\n",
    "    denominator = {}\n",
    "    for c in C:                                                                           # calculate total number of words/terms\n",
    "        denominator[c] = 0\n",
    "        for k in vocabulary:\n",
    "            denominator[c] += vocabulary[k][c] + 1                                        # apply laplace smoothing by add 1 to each count\n",
    "    for c in C:\n",
    "        for k in vocabulary:\n",
    "            condprob[k][c] = (vocabulary[k][c] + 1) / denominator[c]\n",
    "            \n",
    "        \n",
    "    return vocabulary, prior, condprob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ApplyMultinomialNB(C, V, prior, condprob, d):\n",
    "    \n",
    "    no_remove = \"\"\n",
    "    punctuations = list(string.punctuation)\n",
    "    stop_words = stopwords.words('english')\n",
    "    stop_words_punc = stopwords.words('english') + list(string.punctuation)\n",
    "    myFilter = no_remove\n",
    "\n",
    "    score = {c: math.log(prior[c]) for c in C}\n",
    "    \n",
    "    file = open(d, 'r', encoding='utf-8', errors='ignore')\n",
    "    text = file.read().lower()\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered_keys = [i for i in word_tokenize(text) if i not in myFilter]\n",
    "    \n",
    "    for c in C:\n",
    "        for k in filtered_keys:\n",
    "            if k in V: \n",
    "                score[c] += math.log(condprob[k][c])\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateMultinomialNB(C, D, D_test):\n",
    "    \n",
    "    voc, prior, condprob = TrainMultinomialNB(C, D)\n",
    "    \n",
    "    \n",
    "    # create a dictionary to read all documents' full path and make its class as keys\n",
    "    files = {c: [] for c in C}\n",
    "    # r: root, d: directories, f: files\n",
    "    for r, d, f in os.walk(D_test):\n",
    "        for file in f:\n",
    "            for c in C:\n",
    "                if '.'+c in file:\n",
    "                    files[c].append(os.path.join(r, file))\n",
    "    \n",
    "    result = {c: {'positive': 0, 'negative': 0, 'accuracy': 0} for c in C}\n",
    "    for c in C:\n",
    "        for f in files[c]:\n",
    "            score = ApplyMultinomialNB(C, voc, prior, condprob, f)\n",
    "            if score[c] == max(score.values()):\n",
    "                result[c]['positive'] += 1\n",
    "            else:\n",
    "                result[c]['negative'] += 1\n",
    "\n",
    "    pos = 0\n",
    "    neg = 0\n",
    "    for c in C:\n",
    "        result[c]['accuracy'] = result[c]['positive'] / (result[c]['positive'] + result[c]['negative'])\n",
    "        pos += result[c]['positive']\n",
    "        neg += result[c]['negative']\n",
    "    \n",
    "    overall = pos / (pos + neg)\n",
    "    \n",
    "    return result, overall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = [\"spam\", \"ham\"]\n",
    "D = \"./train/\"\n",
    "D_test = \"./test/\"\n",
    "\n",
    "# voc, prior, condprob = TrainMultinomialNB(C, D)\n",
    "\n",
    "result, overall = evaluateMultinomialNB(C, D, D_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------\n",
      "Multinomial Naive Bayes\n",
      "----------------------------------------------------------\n",
      "Words filter:\t\tnone\n",
      "\n",
      "Result: \n",
      "  spam: \n",
      "\tpositive:\t117\n",
      "\tnegative:\t13\n",
      "\taccuracy: 90.0000%\n",
      "  ham: \n",
      "\tpositive:\t337\n",
      "\tnegative:\t11\n",
      "\taccuracy: 96.8391%\n",
      "  overall: \n",
      "\taccuracy: 94.9791%\n",
      "----------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Multinomial Naive Bayes\")\n",
    "print(\"----------------------------------------------------------\")\n",
    "print(\"Words filter:\\t\\tnone\\n\")\n",
    "print(\"Result: \")\n",
    "print(\"  spam: \")\n",
    "print(\"\\tpositive:\\t\" + str(result['spam']['positive']) + \"\\n\\tnegative:\\t\" + str(result['spam']['negative']))\n",
    "print(\"\\taccuracy: \" + \"{:.4%}\".format(result['spam']['accuracy']))\n",
    "print(\"  ham: \")\n",
    "print(\"\\tpositive:\\t\" + str(result['ham']['positive']) + \"\\n\\tnegative:\\t\" + str(result['ham']['negative']))\n",
    "print(\"\\taccuracy: \" + \"{:.4%}\".format(result['ham']['accuracy']))\n",
    "print(\"  overall: \")\n",
    "print(\"\\taccuracy: \" + \"{:.4%}\".format(overall))\n",
    "print(\"----------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
